{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e4827cc0",
   "metadata": {},
   "source": [
    "# Cell Neuclei Detection using Semantic Segmentation with U-Net"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c672a08",
   "metadata": {},
   "source": [
    "## 1. Import Neccesary Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f5cc909",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd \n",
    "import matplotlib.pyplot as plt\n",
    "import glob\n",
    "import pathlib\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "import time\n",
    "import datetime"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "078035c2",
   "metadata": {},
   "source": [
    "## 2. Data Preprocessing and loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cca981b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_dir = 'G:/My Drive/Colab Notebooks/Project/Inputs/data-science-bowl-2018/'\n",
    "unzip_base_dir = 'G:/My Drive/Colab Notebooks/Project/Inputs/Working'\n",
    "stage_train_zip = base_dir + 'stage1_train.zip'\n",
    "stage_train_labels_zip= base_dir + 'stage1_train_labels.csv.zip'\n",
    "\n",
    "stage_train_unzip = unzip_base_dir + 'stage1_train/'\n",
    "stage_train_labels_unzip= unzip_base_dir + 'stage1_train_labels/'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9843cc9",
   "metadata": {},
   "source": [
    "### 2.1 Unzip the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fdeafce",
   "metadata": {},
   "outputs": [],
   "source": [
    "import zipfile\n",
    "for path, unzip_path in zip([stage_train_zip,stage_train_labels_zip ], [stage_train_unzip, stage_train_labels_unzip]):\n",
    "    print(path)\n",
    "    print(unzip_path)\n",
    "    print('---')\n",
    "    with zipfile.ZipFile(path, 'r') as zip_ref:\n",
    "        zip_ref.extractall(unzip_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e37972c",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data = r\"G:\\My Drive\\Colab Notebooks\\Project\\Inputs\\data-science-bowl-2018\\stage1_test.zip\"\n",
    "test_data_unzip = unzip_base_dir + 'stage1_test/'\n",
    "with zipfile.ZipFile(test_data, 'r') as zip_ref:\n",
    "    zip_ref.extractall(test_data_unzip)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7aa313e",
   "metadata": {},
   "outputs": [],
   "source": [
    "test = pathlib.Path(test_data_unzip)\n",
    "lsttest_files = glob.glob(str(test/'*/'))\n",
    "lsttest_files[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82c63bb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_image(image_path):\n",
    "    temp_path = glob.glob(image_path+'/images/*')\n",
    "    img = tf.io.read_file(temp_path[0])\n",
    "    img = tf.io.decode_image(img)\n",
    "    img = tf.image.resize(img, (128,128))\n",
    "\n",
    "    arr = img[:, :, :3].numpy()\n",
    "    new_arr = ((arr - arr.min()) * (1/(arr.max() - arr.min())))\n",
    "    return new_arr\n",
    "\n",
    "test_images = []\n",
    "for i in lsttest_files:\n",
    "    test_images.append(get_image(i))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d48bb68",
   "metadata": {},
   "source": [
    "###  2.2 Convert the images to the tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05d158c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dataset = tf.convert_to_tensor(np.array(test_images))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d782d3ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = pathlib.Path(stage_train_unzip)\n",
    "lst_files = glob.glob(str(path/'*/'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aadbd51a",
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d953ab7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class create_ds(keras.utils.Sequence):\n",
    "    def __init__(self, lst_files, batch_size):\n",
    "        self.lst_files = lst_files\n",
    "        self.batch_size = batch_size\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.lst_files)//self.batch_size\n",
    "\n",
    "    \n",
    "    def get_image(self, image_path):\n",
    "        temp_path = glob.glob(image_path+'/images/*')\n",
    "        img = tf.io.read_file(temp_path[0])\n",
    "        img = tf.io.decode_image(img)\n",
    "        img = tf.image.resize(img, (128,128))\n",
    "\n",
    "        arr = img[:, :, :3].numpy()\n",
    "        new_arr = ((arr - arr.min()) * (1/(arr.max() - arr.min())))\n",
    "        \n",
    "        ma = glob.glob(image_path+'/masks/*')\n",
    "        mask_ = tf.zeros(shape = (128, 128, 1))\n",
    "        \n",
    "        # Get all mask in particular folder and append to mask with all pixel value equal to zero\n",
    "        for mask_path in ma:\n",
    "            mask = tf.io.read_file(mask_path)\n",
    "            mask = tf.io.decode_image(mask)\n",
    "            mask = tf.image.resize(mask, (128,128))\n",
    "           \n",
    "            mask_ = tf.maximum(mask_, mask)\n",
    "        \n",
    "        return new_arr, mask_.numpy()\n",
    "        \n",
    "    # Create batches of given batch and return to the dataset object    \n",
    "    def __getitem__(self, idx):\n",
    "        batch = self.lst_files[idx * self.batch_size : (idx+1)*self.batch_size]\n",
    "        \n",
    "        temp_image = []\n",
    "        temp_label = []\n",
    "        for path in batch:\n",
    "            new_arr, mask = self.get_image(path)\n",
    "            temp_image.append(new_arr)\n",
    "            temp_label.append(mask/255.0)\n",
    "        \n",
    "        return tf.convert_to_tensor(np.array(temp_image), dtype='float32'), tf.convert_to_tensor(np.array(temp_label),dtype ='float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "baeff98c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.graph_objects as go\n",
    "\n",
    "# We will pass the df which we created using model.history, So we wo=ill plot train, test loss. Train test accuracy\n",
    "def plot_train_valid_curcve(df):\n",
    "        fig = go.Figure()\n",
    "        fig.add_trace(go.Scatter(x=list(range(len(df))), y=df['loss'],\n",
    "                            mode='lines',\n",
    "                            name='Train_loss'))\n",
    "\n",
    "        fig.add_trace(go.Scatter(x=list(range(len(df))), y=df['val_loss'],\n",
    "                            mode='lines',\n",
    "                            name='val_loss'))\n",
    "\n",
    "        fig.add_trace(go.Scatter(x=list(range(len(df))), y=df['accuracy'],\n",
    "                            mode='lines',\n",
    "                            name='Train_accuracy'))\n",
    "\n",
    "        fig.add_trace(go.Scatter(x=list(range(len(df))), y=df['val_accuracy'],\n",
    "                            mode='lines',\n",
    "                            name='val_accuracy'))\n",
    "        fig.show()\n",
    "        \n",
    "# Let's see what we got as a prediction\n",
    "def plot_predicted_image(x_test, valid, pred):\n",
    "    ''' Function to plot Actual image, actual mask, Predicted Mask\n",
    "    \n",
    "    Param X-test : Actual image\n",
    "    Param valid  : Validation mask\n",
    "    Param pred   : Predicted image\n",
    "    '''\n",
    "    \n",
    "    fig = plt.figure(figsize = (15,7))\n",
    "    plt.subplot(1, 3,1)\n",
    "    plt.title('Actual Image')\n",
    "    plt.imshow(x_test)\n",
    "    \n",
    "#     fig = plt.figure(figsize = (20,7))\n",
    "    plt.subplot(1, 3,2)\n",
    "    plt.title('Actual Mask')\n",
    "    plt.imshow(valid)\n",
    "    \n",
    "    plt.subplot(1, 3,3)\n",
    "    plt.title('Predicted mask')\n",
    "    plt.imshow(pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3808c749",
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's split the data into train test split\n",
    "from sklearn.model_selection import train_test_split\n",
    "train, valid = train_test_split(lst_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b952512f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating the data using the class we created where we leverage the functionality of keras.sequence\n",
    "train_ds = create_ds(lst_files=train, batch_size = BATCH_SIZE) \n",
    "valid_ds= create_ds(lst_files=valid, batch_size = BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffba4a61",
   "metadata": {},
   "source": [
    "## 3. Model 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9363db4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# the dimension of image\n",
    "IMAGE_HEIGHT=128\n",
    "IMAGE_WIDTH=128\n",
    "CHANNEL = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5310ff42",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model(IMAGE_HEIGHT, IMAGE_WIDTH, CHANNEL):\n",
    "    inputs = keras.Input(shape = (IMAGE_HEIGHT, IMAGE_WIDTH, CHANNEL))\n",
    "    conv_1 = keras.layers.Conv2D(filters = 16, kernel_size = 3, padding='same', activation='relu')(inputs)\n",
    "    conv_1 = keras.layers.Conv2D(filters = 16, kernel_size = 3, padding='same', activation='relu')(conv_1)\n",
    "    # conv_1\n",
    "\n",
    "    conv_2 = keras.layers.MaxPool2D(pool_size = (2,2))(conv_1)\n",
    "    conv_2 = keras.layers.Conv2D(filters = 32, kernel_size = 3, padding='same', activation='relu')(conv_2)\n",
    "    conv_2 = keras.layers.Conv2D(filters = 32, kernel_size = 3, padding='same', activation='relu')(conv_2)\n",
    "\n",
    "    conv_3 = keras.layers.MaxPool2D(pool_size = (2,2))(conv_2)\n",
    "    conv_3 = keras.layers.Conv2D(filters = 64, kernel_size = 3, padding='same', activation='relu')(conv_3)\n",
    "    conv_3 = keras.layers.Conv2D(filters = 64, kernel_size = 3, padding='same', activation='relu')(conv_3)\n",
    "\n",
    "    conv_4 = keras.layers.MaxPool2D(pool_size = (2,2))(conv_3)\n",
    "    conv_4 = keras.layers.Conv2D(filters = 128, kernel_size = 3, padding='same', activation='relu')(conv_4)\n",
    "    conv_4 = keras.layers.Conv2D(filters = 128, kernel_size = 3, padding='same', activation='relu')(conv_4)\n",
    "\n",
    "    conv_5 = keras.layers.MaxPool2D(pool_size = (2,2))(conv_4)\n",
    "    conv_5 = keras.layers.Conv2D(filters = 256, kernel_size = 3, padding='same', activation='relu')(conv_5)\n",
    "    conv_5 = keras.layers.Conv2D(filters = 256, kernel_size = 3, padding='same', activation='relu')(conv_5)\n",
    "    \n",
    "    conv_6 = keras.layers.Conv2DTranspose(filters = 128, kernel_size = 2, strides = 2, padding='same')(conv_5)\n",
    "    conv_6 = keras.layers.concatenate([conv_4, conv_6])\n",
    "    conv_6 = keras.layers.Conv2D(filters = 128, kernel_size = 3, padding='same', activation='relu')(conv_6)\n",
    "    conv_6 = keras.layers.Conv2D(filters = 128, kernel_size = 3, padding='same', activation='relu')(conv_6)\n",
    "\n",
    "    conv_7 = keras.layers.Conv2DTranspose(filters = 64, kernel_size = 2, strides = 2, padding='same')(conv_6)\n",
    "    conv_7 = keras.layers.concatenate([conv_3, conv_7])\n",
    "    conv_7 = keras.layers.Conv2D(filters = 64, kernel_size = 3, padding='same', activation='relu')(conv_7)\n",
    "    conv_7 = keras.layers.Conv2D(filters = 64, kernel_size = 3, padding='same', activation='relu')(conv_7)\n",
    "\n",
    "    conv_8 = keras.layers.Conv2DTranspose(filters = 32, kernel_size = 2, strides = 2, padding='same')(conv_7)\n",
    "    conv_8 = keras.layers.concatenate([conv_2, conv_8])\n",
    "    conv_8 = keras.layers.Conv2D(filters = 32, kernel_size = 3, padding='same', activation='relu')(conv_8)\n",
    "    conv_8 = keras.layers.Conv2D(filters = 32, kernel_size = 3, padding='same', activation='relu')(conv_8)\n",
    "\n",
    "\n",
    "    conv_9 = keras.layers.Conv2DTranspose(filters = 16, kernel_size = 2, strides = 2, padding='same')(conv_8)\n",
    "    conv_9 = keras.layers.concatenate([conv_1, conv_9])\n",
    "    conv_9 = keras.layers.Conv2D(filters = 16, kernel_size = 3, padding='same', activation='relu')(conv_9)\n",
    "    conv_9 = keras.layers.Conv2D(filters = 16, kernel_size = 3, padding='same', activation='relu')(conv_9)\n",
    "\n",
    "    output = keras.layers.Conv2D(filters = 1, kernel_size = 3, padding='same', activation='relu')(conv_9)\n",
    "    model = keras.Model(inputs, output)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aced9c49",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = get_model(IMAGE_HEIGHT, IMAGE_WIDTH, CHANNEL)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e83d607",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer = 'adam', loss = 'binary_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbc69f87",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create a function to display some examples\n",
    "def display(display_list):\n",
    "    plt.figure(figsize=(15,15))\n",
    "    title = ['Input Image','True Mask','Predicted Mask']\n",
    "    \n",
    "    for i in range(len(display_list)):\n",
    "        plt.subplot(1, len(display_list),i+1)\n",
    "        plt.title(title[i])\n",
    "        plt.imshow(tf.keras.utils.array_to_img(display_list[i]))\n",
    "        plt.axis('off')\n",
    "        \n",
    "    plt.show()\n",
    "    \n",
    "for images, masks in train.take(2):\n",
    "    sample_image, sample_mask = images[0], masks[0]\n",
    "    display([sample_image,sample_mask])\n",
    "    \n",
    "#Create a function to process predicted mask\n",
    "def create_mask(pred_mask):\n",
    "    pred_mask = tf.argmax(pred_mask,axis=-1)\n",
    "    pred_mask = pred_mask[..., tf.newaxis]\n",
    "    return pred_mask\n",
    "\n",
    "#Create a function to display prediction\n",
    "def show_predictions(dataset=None,num=1):\n",
    "    if dataset:\n",
    "        for image, mask in dataset.take(num):\n",
    "            pred_mask = model.predict(image)\n",
    "            display([image[0],mask[0],create_mask(pred_mask)[0]])\n",
    "    else:\n",
    "        display([sample_image,sample_mask,create_mask(model.predict(sample_image[tf.newaxis,...]))[0]])\n",
    "\n",
    "#Custom callback to display result during training\n",
    "class DisplayCallback(tf.keras.callbacks.Callback):\n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        clear_output(wait=True)\n",
    "        show_predictions()\n",
    "        print('\\n Sample prediction after epoch {}\\n'.format(epoch+1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "913c0ac1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Tensorboard callback\n",
    "base_log_path = r\"G:/My Drive/Colab Notebooks/Project/Inputs/Log\"\n",
    "log_dir = os.path.join(base_log_path, datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\"))\n",
    "tb_callback = tf.keras.callbacks.TensorBoard(log_dir,histogram_freq=1,profile_batch=0)\n",
    "\n",
    "# We will create baseline model and execute for 10 epochs\n",
    "history = model.fit(train_ds,epochs=10,batch_size=64,\n",
    "                    validation_data=valid_ds,\n",
    "                    callbacks=[DisplayCallback(),tb_callback])\n",
    "#history = model.fit(train_ds, validation_data=valid_ds, epochs = 10, verbose=False, callbacks=tb_callback)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6a1879e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(history.history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "658777b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_train_valid_curcve(df)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
